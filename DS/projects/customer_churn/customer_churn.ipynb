{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44594d66-071c-4b4d-a9a4-1f2a62b9331c",
   "metadata": {},
   "source": [
    "# Assessing Customer Churn Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd466f9-a72a-44df-9e00-6926a97a4923",
   "metadata": {},
   "source": [
    "![Cartoon of telecom customers](IMG_8811.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa483a-e084-4ba8-9236-5c0468364e0d",
   "metadata": {},
   "source": [
    "The telecommunications (telecom) sector in India is rapidly changing, with more and more telecom businesses being created and many customers deciding to switch between providers. \"Churn\" refers to the process where customers or subscribers stop using a company's services or products. Understanding the factors that influence keeping a customer as a client in predicting churn is crucial for telecom companies to enhance their service quality and customer satisfaction. As the data scientist on this project, you aim to explore the intricate dynamics of customer behavior and demographics in the Indian telecom sector in predicting customer churn, utilizing two comprehensive datasets from four major telecom partners: Airtel, Reliance Jio, Vodafone, and BSNL:\n",
    "\n",
    "- `telecom_demographics.csv` contains information related to Indian customer demographics:\n",
    "\n",
    "| Variable             | Description                                      |\n",
    "|----------------------|--------------------------------------------------|\n",
    "| `customer_id `         | Unique identifier for each customer.             |\n",
    "| `telecom_partner `     | The telecom partner associated with the customer.|\n",
    "| `gender `              | The gender of the customer.                      |\n",
    "| `age `                 | The age of the customer.                         |\n",
    "| `state`                | The Indian state in which the customer is located.|\n",
    "| `city`                 | The city in which the customer is located.       |\n",
    "| `pincode`              | The pincode of the customer's location.          |\n",
    "| `registration_event` | When the customer registered with the telecom partner.|\n",
    "| `num_dependents`      | The number of dependents (e.g., children) the customer has.|\n",
    "| `estimated_salary`     | The customer's estimated salary.                 |\n",
    "\n",
    "- `telecom_usage` contains information about the usage patterns of Indian customers:\n",
    "\n",
    "| Variable   | Description                                                  |\n",
    "|------------|--------------------------------------------------------------|\n",
    "| `customer_id` | Unique identifier for each customer.                         |\n",
    "| `calls_made` | The number of calls made by the customer.                    |\n",
    "| `sms_sent`   | The number of SMS messages sent by the customer.             |\n",
    "| `data_used`  | The amount of data used by the customer.                     |\n",
    "| `churn`    | Binary variable indicating whether the customer has churned or not (1 = churned, 0 = not churned).|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ba995-969a-4361-946f-63ef11957687",
   "metadata": {},
   "source": [
    "### Project Requirements\n",
    "\n",
    "Does Logistic Regression or Random Forest produce a higher accuracy score in predicting telecom churn in India?\n",
    "\n",
    "Load the two CSV files into separate DataFrames. Merge them into a DataFrame named churn_df. Calculate and print churn rate, and identify the categorical variables in churn_df.\n",
    "Convert categorical features in churn_df into features_scaled. Perform feature scaling separating the appropriate features and scale them. Define your scaled features and target variable for the churn prediction model.\n",
    "Split the processed data into training and testing sets giving names of X_train, X_test, y_train, and y_test using an 80-20 split, setting a random state of 42 for reproducibility.\n",
    "Train Logistic Regression and Random Forest Classifier models, setting a random seed of 42. Store model predictions in logreg_pred and rf_pred.\n",
    "Assess the models on test data. Assign the model's name with higher accuracy (\"LogisticRegression\" or \"RandomForest\") to higher_accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e5adf-dc71-46bf-9820-e10c3ea18ff7",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95efd3c7-a48a-49c2-9df6-36f078de3b38",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 9,
    "lastExecutedAt": 1699920392111,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries and methods/functions\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Start your code here!"
   },
   "outputs": [],
   "source": [
    "# Import libraries and methods/functions\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Start your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75e1a0-341b-411d-ab16-a8824272166b",
   "metadata": {},
   "source": [
    "### How to approach this project?\n",
    "\n",
    "1. Loading and exploring data\n",
    "\n",
    "2. Processing the joined data\n",
    "\n",
    "3. Splitting the data\n",
    "\n",
    "4. Getting the predictions\n",
    "\n",
    "5. Assessing the models\n",
    "\n",
    "6. Identifying which model has higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc29a45-94f6-4d6d-87a4-11b82d44313b",
   "metadata": {},
   "source": [
    "### 1. Loading and exploring data\n",
    "\n",
    "You should load the telecom_demographics.csv and telecom_usage.csv datasets, join them, calculate the proportion of churn, and identify categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3e337-7e83-4018-a676-220a25a04e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "telco_demog = pd.read_csv('telecom_demographics.csv')\n",
    "telco_usage = pd.read_csv('telecom_usage.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d98390-2fca-4b26-be9d-8fbdf23eca43",
   "metadata": {},
   "source": [
    "### 2. Processing the joined data\n",
    "\n",
    "You should convert categorical variables into numerical representations, standardize all relevant features, and then define your target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ee57a-f6d7-4010-925f-312bc6884cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data\n",
    "churn_df = telco_demog.merge(telco_usage, on='customer_id')\n",
    "\n",
    "# Identify churn rate\n",
    "churn_rate = churn_df['churn'].value_counts() / len(churn_df)\n",
    "print(churn_rate)\n",
    "\n",
    "# Identify categorical variables\n",
    "print(churn_df.info())\n",
    "\n",
    "# One Hot Encoding for categorical variables\n",
    "churn_df = pd.get_dummies(churn_df, columns=['telecom_partner', 'gender', 'state', 'city', 'registration_event'])\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 'customer_id' is not a feature\n",
    "features = churn_df.drop(['customer_id', 'churn'], axis=1)\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Target variable\n",
    "target = churn_df['churn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1bd2e-1a68-4036-a58a-e960b1810854",
   "metadata": {},
   "source": [
    "### 3. Splitting the data\n",
    "\n",
    "You should split the standardized features and the defined target variable into an 80-20 training and testing split assigning a random state of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfebf6-d2c3-4fd5-b9cf-1403f0e91cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3657b1-49ec-4cdf-8fde-0b80bc6de5ce",
   "metadata": {},
   "source": [
    "### 4. Getting the predictions\n",
    "\n",
    "You should instantiate, fit, and produce predictions for each of the Logistic Regression and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ad3fd-5b78-4ea7-8f9a-409ba8ff50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression predictions\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# Logistic Regression evaluation\n",
    "print(confusion_matrix(y_test, logreg_pred))\n",
    "print(classification_report(y_test, logreg_pred))\n",
    "\n",
    "# Instantiate the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest predictions\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ac6ce-672d-4d76-a6c2-0baec8c7d16b",
   "metadata": {},
   "source": [
    "### 5. Assessing the models\n",
    "\n",
    "You should print confusion matrices and classification reports for each of the Logistic Regression and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc09702-217b-4806-8a3f-e2c9e4e9c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest evaluation\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411bdeb-c428-4b3b-acae-300dcdd18e76",
   "metadata": {},
   "source": [
    "### 6. Identifying which model has higher accuracy\n",
    "\n",
    "You should look at the classification reports to see which accuracy score is closer to 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd9fcd-c03a-4049-b3b7-b2561982e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which accuracy score is higher? Ridge or RandomForest\n",
    "higher_accuracy = \"RandomForest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4226-1544-4e82-9f86-7bbef650f3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2e689-0025-45dc-9ae8-4cf1320db3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb67407-af15-4d8d-bba8-b0a55e29139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19662c-a90f-42d3-818a-003743028919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
